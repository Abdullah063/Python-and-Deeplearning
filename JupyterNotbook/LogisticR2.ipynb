{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef630511-1885-44f5-af15-fe9828c2b40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a223872-4148-456d-946b-5dbb22de81ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cihaz Kontrolü (GPU Kullanımı)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2c461c2-cb58-40b7-a6f0-f656f0bf5489",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Hiperparametreler\n",
    "num_epochs = 10\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "# MNIST Veri Kümesini Yükleme ve Normalizasyon\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f778ec1a-2c60-4b9e-a56b-d3f22ff55a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 9.91M/9.91M [00:05<00:00, 1.79MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 28.9k/28.9k [00:00<00:00, 159kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1.65M/1.65M [00:01<00:00, 1.34MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 4.54k/4.54k [00:00<00:00, 2.73MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6808539-bdf2-4528-a263-d26c89966f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lojistik Regresyon Modeli\n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "632958c1-b864-451e-9ebf-66321a7cb0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeli Tanımla ve Cihaza Gönder\n",
    "input_dim = 28*28  # MNIST görselleri 28x28 boyutundadır\n",
    "output_dim = 10    # 0-9 arasındaki rakamlar için\n",
    "model = LogisticRegressionModel(input_dim, output_dim).to(device)\n",
    "\n",
    "# Kayıp Fonksiyonu ve Optimizasyon\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9473f17c-6324-4f6e-bd03-fa31d99454a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500, Loss: 1.1516, Accuracy: 78.90%\n",
      "Iteration: 1000, Loss: 0.8488, Accuracy: 83.59%\n",
      "Iteration: 1500, Loss: 0.8949, Accuracy: 85.27%\n",
      "Iteration: 2000, Loss: 0.5523, Accuracy: 86.20%\n",
      "Iteration: 2500, Loss: 0.6297, Accuracy: 86.61%\n",
      "Iteration: 3000, Loss: 0.5480, Accuracy: 87.23%\n",
      "Iteration: 3500, Loss: 0.5966, Accuracy: 87.49%\n",
      "Iteration: 4000, Loss: 0.7496, Accuracy: 87.88%\n",
      "Iteration: 4500, Loss: 0.5914, Accuracy: 88.23%\n",
      "Iteration: 5000, Loss: 0.4940, Accuracy: 88.34%\n",
      "Iteration: 5500, Loss: 0.4545, Accuracy: 88.51%\n",
      "Iteration: 6000, Loss: 0.4544, Accuracy: 88.76%\n"
     ]
    }
   ],
   "source": [
    "# Model Eğitimi\n",
    "loss_list = []\n",
    "iteration_list = []\n",
    "count = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Görselleri düzleştir ve cihaza (GPU/CPU) gönder\n",
    "        images = images.view(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Gradients sıfırlama\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # İleri Yayılım\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Kayıp Hesaplama\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Geri Yayılım\n",
    "        loss.backward()\n",
    "        \n",
    "        # Parametre Güncelleme\n",
    "        optimizer.step()\n",
    "        \n",
    "        count += 1\n",
    "        \n",
    "        # Her 50 iterasyonda bir doğruluk ölç\n",
    "        if count % 50 == 0:\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            with torch.no_grad():\n",
    "                for images, labels in test_loader:\n",
    "                    images = images.view(-1, 28*28).to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    outputs = model(images)\n",
    "                    predicted = torch.argmax(outputs, dim=1)\n",
    "\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            accuracy = 100 * correct / total\n",
    "            loss_list.append(loss.item())\n",
    "            iteration_list.append(count)\n",
    "\n",
    "            if count % 500 == 0:\n",
    "                print(f'Iteration: {count}, Loss: {loss.item():.4f}, Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66834e66-6a74-47bc-99e6-81b32c1ec63f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (AllProject)",
   "language": "python",
   "name": "allproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
